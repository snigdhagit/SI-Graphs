{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilingh/Desktop/PhD/SI_Codes/SI-Graphs/env3/lib/python3.10/site-packages/regreg/atoms/slope.py:16: UserWarning: unable to import isotonic regression from sklearn, using a pure python implementation\n",
      "  warn('unable to import isotonic regression from sklearn, using a pure python implementation')\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from selectinf.nbd_lasso import nbd_lasso\n",
    "from selectinf.Utils.discrete_family import discrete_family\n",
    "from instance import GGM_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom perturbation\n",
      "Sampled perturbation\n",
      "(10, 9)\n",
      "10.0\n",
      "8.0\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "# TODO: Add root n to the randomization covariance\n",
    "prec,cov,X = GGM_instance(n=500,p=10, max_edges=2)\n",
    "nbd_instance = nbd_lasso.gaussian(X)\n",
    "active_signs_nonrandom = nbd_instance.fit(perturb=np.zeros((10,9)))\n",
    "active_signs_random = nbd_instance.fit()\n",
    "print(active_signs_nonrandom.shape)\n",
    "print(np.abs(active_signs_nonrandom).sum())\n",
    "print(np.abs(active_signs_random).sum())\n",
    "print(np.abs(prec != 0).sum() - 10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002 0.002]\n",
      "[[ 5.00000000e+02  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  5.89115114e+02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -2.29126735e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  5.76169501e+02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  -2.09491153e+02  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  5.54774395e+02\n",
      "   1.65122517e-15  0.00000000e+00  0.00000000e+00  1.74319912e+02\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.41699142e-14\n",
      "   6.31956011e+02  0.00000000e+00  0.00000000e+00 -2.88773951e+02\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  5.59906548e+02 -1.83144939e+02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00 -1.83144939e+02  5.59906548e+02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.74319912e+02\n",
      "  -2.88773951e+02  0.00000000e+00  0.00000000e+00  6.86730406e+02\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00 -2.09491153e+02  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   5.76169501e+02  0.00000000e+00]\n",
      " [ 0.00000000e+00 -2.29126735e+02  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  5.89115114e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(np.diag(cov))\n",
    "print((prec))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def remove_diag(A):\n",
    "    p = A.shape[0]\n",
    "    A_new = np.zeros((p,p-1))\n",
    "    for i in range(p):\n",
    "        A_new[i] = np.delete(A[i],i)\n",
    "    return A_new\n",
    "\n",
    "def add_diag(A,val):\n",
    "    p = A.shape[0]\n",
    "    A_new = np.zeros((p,p))\n",
    "    for i in range(p):\n",
    "        A_new[i,0:i] = A[i,0:i]\n",
    "        A_new[i,i] = val\n",
    "        A_new[i,i+1:p] = A[i,i:p-1]\n",
    "    return A_new\n",
    "\n",
    "def is_sym(A, tol = 1e-8):\n",
    "    return(np.max(np.abs(A-A.T)) < tol)\n",
    "\n",
    "def invert_interval(interval):\n",
    "    interval_new = (interval[1]*-1,interval[0]*-1)\n",
    "    return interval_new"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "8.0\n",
      "2.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "prec_no_diag = remove_diag(prec)\n",
    "print(np.abs(active_signs_nonrandom).sum())\n",
    "print(np.abs(active_signs_random).sum())\n",
    "print(np.abs(active_signs_nonrandom - np.sign(-prec_no_diag)).sum())\n",
    "print(np.abs(active_signs_random - np.sign(-prec_no_diag)).sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def bootstrap_variance(X, b_max=500):\n",
    "    n,p = X.shape\n",
    "    S_boot = np.zeros((b_max, p, p))\n",
    "    for b in range(b_max):\n",
    "        sample_idx = np.random.choice(range(n),replace=True,size=n)\n",
    "        X_b = X[sample_idx]\n",
    "        S_boot[b,:,:] = X_b.T @ X_b\n",
    "    # Upper-triangular!\n",
    "    inner_vars = np.zeros((p, p))\n",
    "    for i in range(p):\n",
    "        for j in range(i+1,p):\n",
    "            S_ij_sample = S_boot[:,i,j]\n",
    "            inner_vars[i,j] = np.var(S_ij_sample)\n",
    "    return inner_vars\n",
    "\n",
    "def edge_inference(j0, k0, S, n, p, var=None,\n",
    "                   ngrid=10000):\n",
    "    inner_prod = S[j0,k0]\n",
    "    # print(\"inner_prod\", \"(\", j0, \",\", k0, \"):\" , inner_prod)\n",
    "    # print(\"var:\", var)\n",
    "\n",
    "    stat_grid = np.zeros((1, ngrid))\n",
    "    stat_grid[0,:] = np.linspace(0 - 10*np.sqrt(2/n),#10*np.sqrt(var),\n",
    "                                 0 + 10*np.sqrt(2/n),#10*np.sqrt(var),\n",
    "                                 num=ngrid)\n",
    "    def log_det_S_j_k(s_val):\n",
    "        S_j_k = S\n",
    "        S_j_k[j0,k0] = s_val\n",
    "        S_j_k[k0,j0] = s_val\n",
    "        return (n-p-1)/2 * np.log(np.abs(np.linalg.det(S_j_k)))\n",
    "\n",
    "    logWeights = np.zeros((ngrid,))\n",
    "    for g in range(ngrid):\n",
    "        logWeights[g] = log_det_S_j_k(stat_grid[0,g])\n",
    "    logWeights -= logWeights.max() # not needed anymore after root n scaling\n",
    "\n",
    "    condlWishart = discrete_family(stat_grid[0,:], np.exp(logWeights))\n",
    "\n",
    "    neg_interval = condlWishart.equal_tailed_interval(observed=inner_prod,\n",
    "                                                      alpha=0.1)\n",
    "    return neg_interval, condlWishart\n",
    "\n",
    "def get_nonzero(active_signs):\n",
    "    active_sign_sq = add_diag(active_signs, 0)\n",
    "    nonzero = ((active_sign_sq + active_sign_sq.T) != 0) # OR\n",
    "    # nonzero = ((active_sign_sq * active_sign_sq.T) != 0) # AND\n",
    "    return nonzero\n",
    "\n",
    "def conditional_inference(X,nonzero):\n",
    "    n,p = X.shape\n",
    "\n",
    "    # Estimating variances by bootstrap\n",
    "    # inner_vars = bootstrap_variance(X)\n",
    "    S_ = X.T @ X\n",
    "    intervals = np.zeros((p,p,2))\n",
    "    condlDists = {}\n",
    "    for i in range(p):\n",
    "        for j in range(i+1,p):\n",
    "            if nonzero[i,j]:\n",
    "                neg_int, condlWishart = edge_inference(j0=i, k0=j, S=S_,\n",
    "                                                       # var=inner_vars[i, j],\n",
    "                                                       n=n, p=p, ngrid=100000)\n",
    "                print(neg_int)\n",
    "                interval = invert_interval(neg_int)\n",
    "                intervals[i,j,:] = interval\n",
    "                condlDists[(i,j)] = condlWishart\n",
    "\n",
    "    return intervals, condlDists"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198.96928557426133, 295.5222207137424)\n",
      "(183.76880468273202, 282.6482160196048)\n",
      "(-233.13573606288455, -139.43801853094382)\n",
      "(683.2613072359356, 887.8466664530948)\n",
      "(209.2491537213587, 309.28009852294474)\n"
     ]
    }
   ],
   "source": [
    "nonzero = get_nonzero(active_signs_nonrandom)\n",
    "\n",
    "intervals,condlDists = \\\n",
    "    conditional_inference(X, nonzero)\n",
    "\n",
    "def get_coverage(nonzero, intervals, prec, p):\n",
    "    coverage = np.zeros((p,p))\n",
    "    for i in range(p):\n",
    "        for j in range(i+1,p):\n",
    "            if nonzero[i,j]:\n",
    "                interval = intervals[i,j,:]\n",
    "                if prec[i,j] < interval[1] and prec[i,j] > interval[0]:\n",
    "                    coverage[i,j] = 1\n",
    "                else:\n",
    "                    coverage[i,j] = 0\n",
    "    return coverage\n",
    "\n",
    "coverage = get_coverage(nonzero, intervals, prec, X.shape[1])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(coverage)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def naive_inference(X):\n",
    "    n,p = X.shape\n",
    "    nbd_instance = nbd_lasso.gaussian(X)\n",
    "    active_signs_nonrandom = nbd_instance.fit(perturb=np.zeros((p,p-1)))\n",
    "    nonzero = get_nonzero(active_signs_nonrandom)\n",
    "\n",
    "    # Construct intervals\n",
    "    if nonzero.sum() > 0:\n",
    "        intervals, condlDists = conditional_inference(X, nonzero)\n",
    "        # coverage is upper-triangular\n",
    "        coverage = get_coverage(nonzero, intervals, prec, p)\n",
    "        interval_len = 0\n",
    "        nonzero_count = 0\n",
    "        for i in range(p):\n",
    "            for j in range(i+1,p):\n",
    "                if nonzero[i,j]:\n",
    "                    interval = intervals[i,j,:]\n",
    "                    interval_len = interval_len + (interval[1] - interval[0])\n",
    "                    nonzero_count = nonzero_count + 1\n",
    "        avg_len = interval_len / nonzero_count\n",
    "        cov_rate = coverage.sum() / nonzero_count\n",
    "        return intervals, cov_rate, avg_len/n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def print_nonzero_intervals(nonzero, intervals, prec, X):\n",
    "    S = X.T @ X\n",
    "    p = prec.shape[0]\n",
    "    for i in range(p):\n",
    "            for j in range(i+1,p):\n",
    "                if nonzero[i,j]:\n",
    "                    print(\"(\",i,\",\",j,\")\", \"selected\")\n",
    "                    print(\"Theta\", \"(\",i,\",\",j,\")\", \"interval:\", intervals[i,j,:])\n",
    "                    print(\"Theta\", \"(\",i,\",\",j,\")\", prec[i,j])\n",
    "                    print(\"S\", \"(\",i,\",\",j,\")\", S[i,j])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( 1 , 9 ) selected\n",
      "Theta ( 1 , 9 ) interval: [-295.52222071 -198.96928557]\n",
      "Theta ( 1 , 9 ) -229.12673471247834\n",
      "S ( 1 , 9 ) 0.40467213447114153\n",
      "( 2 , 8 ) selected\n",
      "Theta ( 2 , 8 ) interval: [-282.64821602 -183.76880468]\n",
      "Theta ( 2 , 8 ) -209.49115294962394\n",
      "S ( 2 , 8 ) 0.3447896748512277\n",
      "( 3 , 7 ) selected\n",
      "Theta ( 3 , 7 ) interval: [139.43801853 233.13573606]\n",
      "Theta ( 3 , 7 ) 174.31991248685642\n",
      "S ( 3 , 7 ) -0.32755364533420894\n",
      "( 4 , 7 ) selected\n",
      "Theta ( 4 , 7 ) interval: [-887.84666645 -683.26130724]\n",
      "Theta ( 4 , 7 ) -288.7739505511683\n",
      "S ( 4 , 7 ) 0.5075472995995413\n",
      "( 5 , 6 ) selected\n",
      "Theta ( 5 , 6 ) interval: [-309.28009852 -209.24915372]\n",
      "Theta ( 5 , 6 ) -183.14493899726764\n",
      "S ( 5 , 6 ) 0.3943756713338829\n"
     ]
    }
   ],
   "source": [
    "print_nonzero_intervals(nonzero, intervals, prec, X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom perturbation\n",
      "(198.96928557426133, 295.5222207137424)\n",
      "(183.76880468273202, 282.6482160196048)\n",
      "(-233.13573606288455, -139.43801853094382)\n",
      "(683.2613072359356, 887.8466664530948)\n",
      "(209.2491537213587, 309.28009852294474)\n"
     ]
    }
   ],
   "source": [
    "intervals, cov_rate, avg_len = naive_inference(X)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_rate"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "0.23749854721081592"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_len"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
